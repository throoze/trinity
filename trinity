#!/usr/bin/env python
# ------------------------------------------------------------
# trinity
#
# Tokenizer for the trinity language. CI-3725 project.
#
# Authors:
# Victor De Ponte, 05-38087, <rdbvictor19@gmail.com>
# Francisco Martinez, 09-10502, <frammnm@gmail.com>
#
# Usage:
#
# ------------------------------------------------------------
import ply.lex as lex

# List of token names.
reserved = {
    'true'     : 'Tk_true',
    'false'    : 'Tk_false',
    'boolean'  : 'Tk_bool',
    'number'   : 'Tk_num',
    'matrix'   : 'Tk_mat',
    'row'      : 'Tk_row',
    'col'      : 'Tk_col',
    'not'      : 'Tk_not',
    'div'      : 'Tk_div',
    'mod'      : 'Tk_mod',
    'print'    : 'Tk_print',
    'use'      : 'Tk_use',
    'in'       : 'Tk_in',
    'end'      : 'Tk_end',
    'set'      : 'Tk_set',
    'read'     : 'Tk_read',
    'if'       : 'Tk_if',
    'then'     : 'Tk_then',
    'else'     : 'Tk_else',
    'for'      : 'Tk_for',
    'do'       : 'Tk_do',
    'while'    : 'Tk_while',
    'function' : 'Tk_func',
    'return'   : 'Tk_ret',
    'begin'    : 'Tk_beg',
    'program'  : 'Tk_prog'
}

tokens = [
    'Tk_comma',   # ,
    'Tk_colon',   # :
    'Tk_scolon',  # ;
    'Tk_obrace',  # {
    'Tk_cbrace',  # }
    'Tk_opar',    # (
    'Tk_cpar',    # )
    'Tk_obrack',  # [
    'Tk_cbrack',  # ]
    'Tk_and',     # &
    'Tk_or',      # |
    'Tk_asign',   # =
    'Tk_eq',      # ==
    'Tk_neq',     # /=
    'Tk_leq',     # <=
    'Tk_less',    # <
    'Tk_geq',     # >=
    'Tk_great',   # >
    'Tk_plus',    # +
    'Tk_minus',   # -
    'Tk_times',   # *
    'Tk_rdiv',    # /
    'Tk_rmod',    # %
    'Tk_trans',   # '
    'Tk_mplus',   # .+.
    'Tk_mminus',  # .-.
    'Tk_mtimes',  # .*.
    'Tk_mrdiv',   # ./.
    'Tk_mrmod',   # .%.
    'Tk_mdiv',    # .div.
    'Tk_mmod',    # .mod.
    'Tk_quote',   # "
    'Tk_esc'      # \
    ] + list(reserved.values())

# Regular expression rules for simple tokens
t_PLUS    = r'\+'
t_MINUS   = r'-'
t_TIMES   = r'\*'
t_DIVIDE  = r'/'
t_LPAREN  = r'\('
t_RPAREN  = r'\)'

# A regular expression rule with some action code
def t_NUMBER(t):
    r'\d+'
    t.value = int(t.value)    
    return t

# Define a rule so we can track line numbers
def t_newline(t):
    r'\n+'
    t.lexer.lineno += len(t.value)

# A string containing ignored characters (spaces and tabs)
t_ignore  = ' \t'

# Error handling rule
def t_error(t):
    print "Illegal character '%s'" % t.value[0]
    t.lexer.skip(1)

# Build the lexer
lexer = lex.lex()