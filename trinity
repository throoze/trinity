#!/usr/bin/env python
# ------------------------------------------------------------
# trinity
#
# Tokenizer for the trinity language. CI-3725 project.
#
# Authors:
# Victor De Ponte, 05-38087, <rdbvictor19@gmail.com>
# Francisco Martinez, 09-10502, <frammnm@gmail.com>
#
# Usage:
#
# ------------------------------------------------------------
import ply.lex as lex

# List of token names.
reserved = {
    'true'     : 'Tk_true',
    'false'    : 'Tk_false',
    'boolean'  : 'Tk_bool',
    'number'   : 'Tk_number',
    'matrix'   : 'Tk_mat',
    'row'      : 'Tk_row',
    'col'      : 'Tk_col',
    'not'      : 'Tk_not',
    'div'      : 'Tk_div',
    'mod'      : 'Tk_mod',
    'print'    : 'Tk_print',
    'use'      : 'Tk_use',
    'in'       : 'Tk_in',
    'end'      : 'Tk_end',
    'set'      : 'Tk_set',
    'read'     : 'Tk_read',
    'if'       : 'Tk_if',
    'then'     : 'Tk_then',
    'else'     : 'Tk_else',
    'for'      : 'Tk_for',
    'do'       : 'Tk_do',
    'while'    : 'Tk_while',
    'function' : 'Tk_func',
    'return'   : 'Tk_ret',
    'begin'    : 'Tk_beg',
    'program'  : 'Tk_prog'
}

tokens = [
    'Tk_id',      # Nombre de variable o función, por ejemplo: foo
    'Tk_num',     # Número literal: 42 y 6.2831853 son números.
    'Tk_comma',   # ,
    'Tk_colon',   # :
    'Tk_scolon',  # ;
    'Tk_obrace',  # {
    'Tk_cbrace',  # }
    'Tk_opar',    # (
    'Tk_cpar',    # )
    'Tk_obrack',  # [
    'Tk_cbrack',  # ]
    'Tk_and',     # &
    'Tk_or',      # |
    'Tk_asign',   # =
    'Tk_eq',      # ==
    'Tk_neq',     # /=
    'Tk_leq',     # <=
    'Tk_less',    # <
    'Tk_geq',     # >=
    'Tk_great',   # >
    'Tk_plus',    # +
    'Tk_minus',   # -
    'Tk_times',   # *
    'Tk_rdiv',    # /
    'Tk_rmod',    # %
    'Tk_trans',   # '
    'Tk_mplus',   # .+.
    'Tk_mminus',  # .-.
    'Tk_mtimes',  # .*.
    'Tk_mrdiv',   # ./.
    'Tk_mrmod',   # .%.
    'Tk_mdiv',    # .div.
    'Tk_mmod',    # .mod.
    'Tk_quote',   # "
    'Tk_esc'      # \
    ] + list(reserved.values())

# Regular expression rules for simple tokens
t_Tk_comma   = r','
t_Tk_colon   = r':'
t_Tk_scolon  = r';'
t_Tk_obrace  = r'{'
t_Tk_cbrace  = r'}'
t_Tk_opar    = r'\('
t_Tk_cpar    = r'\)'
t_Tk_obrack  = r'\['
t_Tk_cbrack  = r'\]'
t_Tk_and     = r'&'
t_Tk_or      = r'\|'
t_Tk_asign   = r'='
t_Tk_eq      = r'=='
t_Tk_neq     = r'/='
t_Tk_leq     = r'<='
t_Tk_less    = r'<'
t_Tk_geq     = r'>='
t_Tk_great   = r'>'
t_Tk_plus    = r'\+'
t_Tk_minus   = r'-'
t_Tk_times   = r'\*'
t_Tk_rdiv    = r'/'
t_Tk_rmod    = r'%'
t_Tk_trans   = r'\''
t_Tk_mplus   = r'\.\+\.'
t_Tkmminus   = r'\.-\.'
t_Tk_mtimes  = r'\.*\.'
t_Tk_mrdiv   = r'\./\.'
t_Tk_mrmod   = r'\.%\.'
t_Tk_mdiv    = r'\.div\.'
t_Tk_mmod    = r'\.mod\.'
t_Tk_quote   = r'"'
t_Tk_esc     = r'\\'

# Token id: a variable or a function name
def t_Tk_id(t):
    r'[a-zA-Z][a-zA-Z0-9]*'
    t.type = reserved.get(t.value,'Tk_id')
    return t

# Token number: an immediate number, according to IEEE 754 
def t_Tk_num(t):
    r'\d+(\.\d+)?'
    t.value = int(t.value)
    return t

# Define a rule so we can track line numbers
def t_newline(t):
    r'\n+'
    t.lexer.lineno += len(t.value)

# A string containing ignored characters (spaces and tabs)
t_ignore  = ' \t'

# Error handling rule
def t_error(t):
    print "Illegal character '%s'" % t.value[0]
    t.lexer.skip(1)

# Build the lexer
lexer = lex.lex()